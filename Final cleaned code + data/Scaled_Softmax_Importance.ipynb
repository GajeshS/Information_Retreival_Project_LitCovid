{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Scaled-Softmax-Importance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48a45240d74642819cb8580b7edb76bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1cd7b967e5d44221b79134649d2d2f20",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbd2dd6d1e8a47f2836e7012ac036b39",
              "IPY_MODEL_4381fd5e54974ae4a6cf222f2ac7a356",
              "IPY_MODEL_df9a84c89bfe4614a0f68f3bd0574536"
            ]
          }
        },
        "1cd7b967e5d44221b79134649d2d2f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbd2dd6d1e8a47f2836e7012ac036b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f3b2c02cd32456eaad03856be15bb2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26d719af141c4d56bc85900f55fdc587"
          }
        },
        "4381fd5e54974ae4a6cf222f2ac7a356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94b07ba0c21b4f6e94ab799bf88fa3b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38f6f437753c4e0ea13f5b73b0d944a8"
          }
        },
        "df9a84c89bfe4614a0f68f3bd0574536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d5da9ab2eb64331aec60c187c44f091",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 352kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e256ae6f625841f3bc041dea5d08ae8a"
          }
        },
        "8f3b2c02cd32456eaad03856be15bb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26d719af141c4d56bc85900f55fdc587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94b07ba0c21b4f6e94ab799bf88fa3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38f6f437753c4e0ea13f5b73b0d944a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d5da9ab2eb64331aec60c187c44f091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e256ae6f625841f3bc041dea5d08ae8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e5fe67b8d5d40969bcb5429c227d458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cd68aa05b0c4c82800403fc182e3bf1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2d181d0501e41979c9b2a968563fc8b",
              "IPY_MODEL_d22f9d89919f4946aa4ce57da94c2301",
              "IPY_MODEL_1274297e94214516b2e7b4f1bf12d246"
            ]
          }
        },
        "7cd68aa05b0c4c82800403fc182e3bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2d181d0501e41979c9b2a968563fc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66c9ef5e840c45b3a65179b80a756c52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7f15f25c0b9414da5ae6a2d05c7d6f0"
          }
        },
        "d22f9d89919f4946aa4ce57da94c2301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae4f0aef1b1c453eab304ff9e702eec9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e532942adc047d7a6143d1ecccb493a"
          }
        },
        "1274297e94214516b2e7b4f1bf12d246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7885b35b90f24b548623c27201923d9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 742B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_630d63334264463e940b6bf34e2269d9"
          }
        },
        "66c9ef5e840c45b3a65179b80a756c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7f15f25c0b9414da5ae6a2d05c7d6f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae4f0aef1b1c453eab304ff9e702eec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e532942adc047d7a6143d1ecccb493a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7885b35b90f24b548623c27201923d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "630d63334264463e940b6bf34e2269d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec9c98c93d264929a6f231544ba8f29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_976bc4d0de7d48828f91f33954f74c7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_740fcbafac254709aee238d778c6f9ab",
              "IPY_MODEL_720361e6a4444ba083b0f18ee4a892fb",
              "IPY_MODEL_444e6ed72d114ebd8f9bb930d298fd9f"
            ]
          }
        },
        "976bc4d0de7d48828f91f33954f74c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "740fcbafac254709aee238d778c6f9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6412ee6decbb445b8383280ef382951c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41f9e96559984d29944a92c7ee2ecb42"
          }
        },
        "720361e6a4444ba083b0f18ee4a892fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40be7d88bcd441deafd31b5e6bdbaf9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be922c462bbc4d408e8b95667aece177"
          }
        },
        "444e6ed72d114ebd8f9bb930d298fd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d5a81e840af439a9f9a2eed1a038cf6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 679kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6a2fd80394042d8a6a97d09c0ec4e52"
          }
        },
        "6412ee6decbb445b8383280ef382951c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41f9e96559984d29944a92c7ee2ecb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40be7d88bcd441deafd31b5e6bdbaf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be922c462bbc4d408e8b95667aece177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d5a81e840af439a9f9a2eed1a038cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6a2fd80394042d8a6a97d09c0ec4e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5604dc40f7c442e8dcfcc8acc6f0d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff33929d902d410ea2f3cf932690b324",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e032f0b5e969438ca15c2b5a8e090ce3",
              "IPY_MODEL_4fcdd2dadc494f65bd4153236f642c2f",
              "IPY_MODEL_335a9c609ba54be38ad820d0e2773114"
            ]
          }
        },
        "ff33929d902d410ea2f3cf932690b324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e032f0b5e969438ca15c2b5a8e090ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad375fe0e96e4caeb63405dcdbf80434",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f67b3d73e5f42249b36b4b923b8d5da"
          }
        },
        "4fcdd2dadc494f65bd4153236f642c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5fb81bcbb38142f086dec35322b2dd4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8eeda67bb09449a1adcb68382020babe"
          }
        },
        "335a9c609ba54be38ad820d0e2773114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1aca9fc119d64620971f899139c7aaf6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 8.73kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d9027e78bda48a1b473c962154dbbf7"
          }
        },
        "ad375fe0e96e4caeb63405dcdbf80434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f67b3d73e5f42249b36b4b923b8d5da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fb81bcbb38142f086dec35322b2dd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8eeda67bb09449a1adcb68382020babe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1aca9fc119d64620971f899139c7aaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d9027e78bda48a1b473c962154dbbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBlzJtlCidsj"
      },
      "source": [
        "### GPU check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEaT7WobEFAg",
        "outputId": "96bbfa5c-4e7f-4b21-f1c2-d700597865ea"
      },
      "source": [
        "# GPU availability check and device initialization\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jbJPa-K_oSZ"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NsoubjfgJMS"
      },
      "source": [
        "### Essential Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e3morQNZNgu"
      },
      "source": [
        "# Importing essential libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcJkawhygOL6"
      },
      "source": [
        "## Data Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl88rnxgjUdn"
      },
      "source": [
        "def split(string):\n",
        "    \"\"\" To split the label values \"\"\"\n",
        "    return str(string).split(';')\n",
        "\n",
        "def preprocess_dataset(df):\n",
        "    \"\"\" Return preprocessed text and labels \"\"\"\n",
        "\n",
        "    # Append the title and abstract information for text\n",
        "    processed_data = pd.DataFrame()\n",
        "    processed_data['labels'] = df['label'].apply(split)\n",
        "    processed_data['text'] = df.apply(lambda row: row['title'] + ' [SEP] ' +row['abstract'],axis=1)\n",
        "    \n",
        "    # Converting labels to One-Hot Encoded list\n",
        "    label_mlb = MultiLabelBinarizer()\n",
        "    label_mle = label_mlb.fit_transform(processed_data['labels'])\n",
        "    processed_data['labels'] = label_mle.tolist()\n",
        "\n",
        "    # Taking and returning the text and label values\n",
        "    text = processed_data.text.values\n",
        "    labels = np.array(list(processed_data.labels.values))\n",
        "    return text, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpXiW2C2lNLJ"
      },
      "source": [
        "def prepare_dataloader(text,labels=np.array([]),is_test_data=False,batch_size=4,val_split=0.05):\n",
        "    \"\"\" Prepare the pytorch DataLoaders for training and validation using the training dataset \"\"\"\n",
        "\n",
        "    # Load the BERT tokenizer.\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "    # Tokenizing text\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    MAX_LEN = 512\n",
        "    for sent in text:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text = sent,   \n",
        "            add_special_tokens = True,         #Add `[CLS]` and `[SEP]`\n",
        "            max_length= MAX_LEN,             #Max length to truncate/pad\n",
        "            pad_to_max_length = True,          #pad sentence to max length \n",
        "            return_attention_mask= True,       #Return attention mask\n",
        "        )\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    \n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    # For the test dataset\n",
        "    if is_test_data==True:\n",
        "        dataset = TensorDataset(input_ids, attention_masks)\n",
        "        dataloader = DataLoader(dataset, shuffle = False, batch_size=batch_size)\n",
        "        return dataloader\n",
        "\n",
        "    # For the training dataset\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "    # Create a train-validation split.\n",
        "    val_size = int(val_split * len(dataset))\n",
        "    train_size = len(dataset) - val_size\n",
        "    # Divide the dataset by randomly selecting samples.\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "    # Print training and validation size\n",
        "    print('{:>5,} training samples'.format(train_size))\n",
        "    print('{:>5,} validation samples'.format(val_size))\n",
        "    \n",
        "    # Creating training and validation dataloaders\n",
        "    train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "    val_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "    return train_dataloader, val_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g8BnER4gfu4"
      },
      "source": [
        "## BERT with Attention Model classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeB-KHlKscJM"
      },
      "source": [
        "class EmbeddingAttention(nn.Module):\n",
        "    def __init__(self, num_input_features, num_hidden_features):\n",
        "        super(EmbeddingAttention,self).__init__()\n",
        "        self.l1 = nn.Linear(num_input_features,num_hidden_features)\n",
        "        self.act_1 = nn.LeakyReLU()\n",
        "        self.l2 = nn.Linear(num_hidden_features, 1) # the final attention weight for the input\n",
        "        self.attn = nn.Softmax(dim=-2) # dim is the second last dim here, since input will have shape (num_samples, token,1)\n",
        "        self.attention_weights = torch.zeros((1,1))\n",
        "    \n",
        "    def getAttentionWeights(self):\n",
        "        return self.attention_weights\n",
        "\n",
        "    def forward(self,x): # input format ==> (m,num_input_features)\n",
        "        l1_out = self.l1(x)\n",
        "        act1_out = self.act_1(l1_out)\n",
        "        individual_attention_weights = self.l2(act1_out)\n",
        "        self.attention_weights = self.attn(individual_attention_weights) * x.shape[-2] # scaling since we do not want all the numbers to be in the ranges of 10^-3 here\n",
        "        return torch.mul(self.attention_weights,x) # broadcasting will happen so final result is elementwide multiplication of (m,1) and (m,num_features) == (m,num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bZTr2ynMTat"
      },
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "        Bert Model for classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param   bert: a BertModel object\n",
        "        @param   classifier: a torch.nn.Module classifier\n",
        "        @param   attention: an attention layer from class EmbeddingAttention\n",
        "        @param   freeze_bert (bool): Set `False` to fine_tune the Bert model\n",
        "        \"\"\"\n",
        "        super(BertClassifier,self).__init__()\n",
        "        # Specify hidden size of Bert, hidden size of our classifier, and number of labels\n",
        "        A_in,A_h = 768,10\n",
        "        C_in,C_h,C_out = 768,50,7\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        self.attention = EmbeddingAttention(A_in, A_h)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "                            nn.Linear(C_in, C_out)\n",
        "                          )\n",
        "\n",
        "        # Freeze the Bert Model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "    \n",
        "    def forward(self,input_ids,attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get the BERT word embeddings\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                           attention_mask = attention_mask)\n",
        "\n",
        "        # Pass all the token embeddings (except CLS) to the attention layer\n",
        "        important_tokens = outputs[0][:,1:,:]\n",
        "        attention_out = self.attention.forward(important_tokens)\n",
        "\n",
        "        # Pool the attention-weighted embeddings of the tokens\n",
        "        mean_att = torch.mean(attention_out,dim=1)\n",
        "\n",
        "        # Feed the pooled document embedding to classifier to compute logits\n",
        "        logit = self.classifier(mean_att)\n",
        "        \n",
        "        return logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBj38pPCgtLH"
      },
      "source": [
        "### Model training helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_yXRqHSg80o"
      },
      "source": [
        "def save_ckp(state):\n",
        "    \"\"\" Save the model at a checkpoint \"\"\"\n",
        "    ep = state['epoch']\n",
        "    f_path = 'checkpoint_ep'+str(ep)+'.pt'\n",
        "    torch.save(state, f_path)\n",
        "    \n",
        "def load_ckp(checkpoint_fpath, model, optimizer,scheduler):\n",
        "    \"\"\" Load the model from a saved checkpoint for further training \"\"\"\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    return model,optimizer,scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hPTG9oMk7a"
      },
      "source": [
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "    \n",
        "    bert_classifier.to(device)\n",
        "    \n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,\n",
        "                      eps=1e-8 #Default epsilon value\n",
        "                     )\n",
        "    \n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    \n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps=0, # Default value\n",
        "                                              num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_iJorLSMvwO"
      },
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\" Set seed for reproducibility. \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\" Train the BertClassifier model. \"\"\"\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "      \n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels.float())\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20--50000 batches\n",
        "            if (step % 50000 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "\n",
        "        # Save checkpoint model after every epoch\n",
        "        checkpoint = {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "        # save_ckp(checkpoint)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        att_weight = model.attention.getAttentionWeights()\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels.float())\n",
        "        val_loss.append(loss.item())\n",
        "        \n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = accuracy_thresh(logits.view(-1,7),b_labels.view(-1,7))      \n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "\n",
        "def accuracy_thresh(y_pred, y_true, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: \n",
        "        y_pred = y_pred.sigmoid()\n",
        "    return ((y_pred>thresh)==y_true.byte()).float().mean().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US77WqvWf4y_"
      },
      "source": [
        "### Predictions and evaluation helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv_1PCFsdOp3"
      },
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities and attention weights\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "    attention_weights = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits and attention weights\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        att_weight = model.attention.getAttentionWeights()\n",
        "        all_logits.append(logits)\n",
        "        attention_weights.append(att_weight)\n",
        "    \n",
        "    # Concatenate logits and weights from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    attention_weights = torch.cat(attention_weights,dim=0)\n",
        "\n",
        "    # Apply sigmoid to calculate probabilities\n",
        "    probs = all_logits.sigmoid().cpu().numpy()\n",
        "\n",
        "    attention_weights_final = attention_weights.cpu().numpy()\n",
        "    \n",
        "    return probs,attention_weights_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTJ8patd78F"
      },
      "source": [
        "def weighted_f1(labels, preds, threshold=0.5):\n",
        "    \"\"\" Converts probabilities to labels using the [threshold] and calculates metrics. \n",
        "    Parameters ---------- labels preds threshold \n",
        "    Returns ------- \"\"\" \n",
        "    preds[preds > threshold] = 1\n",
        "    preds[preds <= threshold] = 0 \n",
        "\n",
        "    scores = f1_score(labels, preds, average='weighted') \n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1CxJCJkC0Hl"
      },
      "source": [
        "### Processing attention weights helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3c4O1pC0aS"
      },
      "source": [
        "def get_attention_weights_for_sample(attention_weights,test_text,sample_index,subwords='sum'):\n",
        "    \"\"\" Return the attention weights for the corresponding words in a sample text given by index \"\"\"\n",
        "    sample_atts = attention_weights[sample_index]\n",
        "    sample_text = test_text[sample_index]\n",
        "\n",
        "    # Getting the text in the tokenized format as processed by BERT\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    encoded_sent = tokenizer.encode_plus(\n",
        "                text = sample_text,   \n",
        "                add_special_tokens = True,         #Add `[CLS]` and `[SEP]`\n",
        "                max_length= 512,             #Max length to truncate/pad\n",
        "                pad_to_max_length = True,          #pad sentence to max length \n",
        "                return_attention_mask= True,       #Return attention mask\n",
        "            )\n",
        "    f_input_ids=encoded_sent.get('input_ids')\n",
        "    f_attention_masks=encoded_sent.get('attention_mask')\n",
        "    f_attention_masks = f_attention_masks[1:]\n",
        "    decoded_f_text = tokenizer.decode(f_input_ids)\n",
        "    decoded_f_text = tokenizer.tokenize(decoded_f_text)\n",
        "    decoded_f_text = decoded_f_text[1:]\n",
        "\n",
        "    # Removing Padded tokens and their corresponding attentions\n",
        "    try:\n",
        "      t = f_attention_masks.index(0)\n",
        "      decoded_f_text = [decoded_f_text[i] for i in range(t)]\n",
        "      sample_atts = [sample_atts[i] for i in range(t)]\n",
        "    except:\n",
        "      print(\"No padded tokens\")\n",
        "\n",
        "    # Getting final attention weights by adding/averaging up weights for the subwords\n",
        "    if subwords=='sum':\n",
        "        final_weights=[]\n",
        "        fullw=0\n",
        "        for i in range(len(decoded_f_text)):\n",
        "          if decoded_f_text[i].find(\"##\")==0:\n",
        "              final_weights[fullw] += sample_atts[i]\n",
        "          else:\n",
        "              final_weights.append(sample_atts[i])\n",
        "              fullw = len(final_weights)-1\n",
        "        final_weights = np.array(final_weights)\n",
        "    elif subwords=='mean':\n",
        "        final_weights=[]\n",
        "        subw_count=1\n",
        "        fullw=0\n",
        "        for i in range(len(decoded_f_text)):\n",
        "          if decoded_f_text[i].find(\"##\")==0:\n",
        "              subw_count+=1\n",
        "              final_weights[fullw] += sample_atts[i]\n",
        "          else:\n",
        "              final_weights.append(sample_atts[i])\n",
        "              final_weights[fullw] /= subw_count\n",
        "              fullw=len(final_weights)-1\n",
        "              subw_count=1\n",
        "        final_weights = np.array(final_weights)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid subwords arg. Choose from : 'sum' or 'mean'\")\n",
        "      \n",
        "    # Getting the final list of words that correspond to the final added attentions\n",
        "    words = tokenizer.convert_tokens_to_string(tokens=decoded_f_text)\n",
        "    words = words.split()\n",
        "\n",
        "    # Asserting for confirmation\n",
        "    assert len(final_weights)==len(words), 'Length mismatch'\n",
        "\n",
        "    return words, final_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0aVfX-igD1A"
      },
      "source": [
        "## Training the model on the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKYAuqOpgZ8Z"
      },
      "source": [
        "### Preprocessing training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwy-ipkA-9Ih",
        "outputId": "f7ba1432-2a98-495d-95c6-500f9332baf3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXi-d32ZmME"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Information Retrieval/BC7-LitCovid-Train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXxHaWxno_3c",
        "outputId": "6563c526-729b-4f20-d409-5a8338d74680"
      },
      "source": [
        "train_text, train_labels = preprocess_dataset(train_data)\n",
        "train_dataloader, val_dataloader = prepare_dataloader(text=train_text,labels=train_labels,batch_size=4,val_split=0.05)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  425 training samples\n",
            "   75 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V3mjddch3GR"
      },
      "source": [
        "### Training..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apRsFsdTYK40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473152dd-484e-4027-96fe-8c67f5fcae4f"
      },
      "source": [
        "# Actual Training cell Prep\n",
        "set_seed(20)\n",
        "epochs=6   # Set number of epochs for training\n",
        "\n",
        " # Initialize the model\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=epochs)\n",
        "\n",
        "# Load the model from a previously saved checkpoint\n",
        "# file = '/content/drive/MyDrive/Information Retrieval/AttentionV1/v1_model.pt'   \n",
        "# load_ckp(file,bert_classifier, optimizer, scheduler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KbiLkBzIzWq"
      },
      "source": [
        "# Train...\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=epochs, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-otqA-ThZmW"
      },
      "source": [
        "## Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fuZlqxMishq"
      },
      "source": [
        "### Preprocess test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238,
          "referenced_widgets": [
            "48a45240d74642819cb8580b7edb76bf",
            "1cd7b967e5d44221b79134649d2d2f20",
            "fbd2dd6d1e8a47f2836e7012ac036b39",
            "4381fd5e54974ae4a6cf222f2ac7a356",
            "df9a84c89bfe4614a0f68f3bd0574536",
            "8f3b2c02cd32456eaad03856be15bb2e",
            "26d719af141c4d56bc85900f55fdc587",
            "94b07ba0c21b4f6e94ab799bf88fa3b7",
            "38f6f437753c4e0ea13f5b73b0d944a8",
            "1d5da9ab2eb64331aec60c187c44f091",
            "e256ae6f625841f3bc041dea5d08ae8a",
            "7e5fe67b8d5d40969bcb5429c227d458",
            "7cd68aa05b0c4c82800403fc182e3bf1",
            "f2d181d0501e41979c9b2a968563fc8b",
            "d22f9d89919f4946aa4ce57da94c2301",
            "1274297e94214516b2e7b4f1bf12d246",
            "66c9ef5e840c45b3a65179b80a756c52",
            "e7f15f25c0b9414da5ae6a2d05c7d6f0",
            "ae4f0aef1b1c453eab304ff9e702eec9",
            "0e532942adc047d7a6143d1ecccb493a",
            "7885b35b90f24b548623c27201923d9d",
            "630d63334264463e940b6bf34e2269d9",
            "ec9c98c93d264929a6f231544ba8f29b",
            "976bc4d0de7d48828f91f33954f74c7f",
            "740fcbafac254709aee238d778c6f9ab",
            "720361e6a4444ba083b0f18ee4a892fb",
            "444e6ed72d114ebd8f9bb930d298fd9f",
            "6412ee6decbb445b8383280ef382951c",
            "41f9e96559984d29944a92c7ee2ecb42",
            "40be7d88bcd441deafd31b5e6bdbaf9e",
            "be922c462bbc4d408e8b95667aece177",
            "0d5a81e840af439a9f9a2eed1a038cf6",
            "b6a2fd80394042d8a6a97d09c0ec4e52",
            "f5604dc40f7c442e8dcfcc8acc6f0d4a",
            "ff33929d902d410ea2f3cf932690b324",
            "e032f0b5e969438ca15c2b5a8e090ce3",
            "4fcdd2dadc494f65bd4153236f642c2f",
            "335a9c609ba54be38ad820d0e2773114",
            "ad375fe0e96e4caeb63405dcdbf80434",
            "7f67b3d73e5f42249b36b4b923b8d5da",
            "5fb81bcbb38142f086dec35322b2dd4b",
            "8eeda67bb09449a1adcb68382020babe",
            "1aca9fc119d64620971f899139c7aaf6",
            "5d9027e78bda48a1b473c962154dbbf7"
          ]
        },
        "id": "rWg_QsI1d4Ap",
        "outputId": "b8ca6935-b462-4086-ff09-aafd2a117984"
      },
      "source": [
        "# Reading and preprocessing test dataset\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Information Retrieval/BC7-LitCovid-Dev.csv')\n",
        "test_text, test_labels = preprocess_dataset(test_data)\n",
        "test_dataloader = prepare_dataloader(text=test_text, batch_size=1, is_test_data=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a45240d74642819cb8580b7edb76bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e5fe67b8d5d40969bcb5429c227d458",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec9c98c93d264929a6f231544ba8f29b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5604dc40f7c442e8dcfcc8acc6f0d4a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilIJeKtnivtu"
      },
      "source": [
        "### Load the trained model (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InXOuGhPd4LB",
        "outputId": "e75b5bab-45ce-4ed5-a295-19dee74ad02f"
      },
      "source": [
        "set_seed(20) # Set seed for reproducibility (same as training)\n",
        "\n",
        "# Initialize the model\n",
        "final_model = BertClassifier(freeze_bert=True)\n",
        "final_model.to(device)\n",
        "\n",
        "# Load model from a file\n",
        "f_file = '/content/drive/MyDrive/Information Retrieval/Bert-Attention-V2/mini_trained_model.pt'\n",
        "ckp = torch.load(f_file)\n",
        "final_model.load_state_dict(ckp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkglQptkizue"
      },
      "source": [
        "### Predictions and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2gJZ5hCeyZp"
      },
      "source": [
        "# Getting the predictions and attention weights on the test set\n",
        "predictions,attention_weights = bert_predict(final_model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYfTM5Z5e9eb",
        "outputId": "dc4e8b6e-3415-41bb-b395-5033eb682cf0"
      },
      "source": [
        "# Evaluating the predictions\n",
        "f1 = weighted_f1(test_labels,predictions)\n",
        "print(\"F1 score :\", f1)\n",
        "lrap_score = label_ranking_average_precision_score(test_labels, predictions)\n",
        "print(\"LRAP score:\",lrap_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score : 0.8875371405027642\n",
            "LRAP score: 0.8869981325863693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-kCaeHzi4yl"
      },
      "source": [
        "## Attention weights analysis..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBHF1EyXzbx3"
      },
      "source": [
        "# If we want to save the attention weights\n",
        "np.savetxt(\"/content/drive/MyDrive/Information Retrieval/Bert-Attention-V2/ep20_atts.txt\",attention_weights)\n",
        "# If we want to load the attention weights\n",
        "attention_weights = np.loadtxt(\"/content/drive/MyDrive/Information Retrieval/Bert-Attention-V2/ep20_atts.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "411ixn7UDPfu"
      },
      "source": [
        "# Flatten\n",
        "attention_weights = attention_weights.reshape((6239,511))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjyo0TdHuzAD",
        "outputId": "eb7bcaaf-177f-44e4-a839-278ffa674730"
      },
      "source": [
        "words,weights = get_attention_weights_for_sample(attention_weights,test_text,sample_index=2400,subwords='sum')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgpbw9oOERJm"
      },
      "source": [
        "### Visualizing attention values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4PJHA4L0eSt"
      },
      "source": [
        "def rescale(input_list):\n",
        "\t\t\"\"\" Function to rescale attention values in the range 0-100 \"\"\"\n",
        "\t\tthe_array = np.asarray(input_list)\n",
        "\t\tthe_max = np.max(the_array)\n",
        "\t\tthe_min = np.min(the_array)\n",
        "\t\trescale = (the_array - the_min)/(the_max-the_min)*100\n",
        "\t\treturn rescale.tolist()\n",
        "\n",
        "def clean_word(word_list):\n",
        "\t\t\"\"\" Function to clean Latex special tokens \"\"\"\n",
        "\t\tnew_word_list = []\n",
        "\t\tfor word in word_list:\n",
        "\t\t\tfor latex_sensitive in [\"\\\\\", \"%\", \"&\", \"^\", \"#\", \"_\",  \"{\", \"}\"]:\n",
        "\t\t\t\tif latex_sensitive in word:\n",
        "\t\t\t\t\tword = word.replace(latex_sensitive, '\\\\'+latex_sensitive)\n",
        "\t\t\tnew_word_list.append(word)\n",
        "\t\treturn new_word_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsxobDRx0eVG"
      },
      "source": [
        "latex_special_token = [\"!@#$%^&*()\"]\n",
        "\n",
        "def generate(text_list, attention_list, latex_file, color='red', rescale_value = False):\n",
        "    \"\"\" Generate attention visualtions as a Latex file \"\"\"\n",
        "    assert(len(text_list) == len(attention_list))\n",
        "    if rescale_value:\n",
        "      attention_list = rescale(attention_list)\n",
        "    word_num = len(text_list)\n",
        "    text_list = clean_word(text_list)\n",
        "    with open(latex_file,'w') as f:\n",
        "      f.write(r'''\\documentclass[varwidth]{standalone}\n",
        "\\special{papersize=210mm,297mm}\n",
        "\\usepackage{color}\n",
        "\\usepackage{tcolorbox}\n",
        "\\usepackage{CJK}\n",
        "\\usepackage{adjustbox}\n",
        "\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n",
        "\\begin{document}\n",
        "\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n",
        "      string = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n",
        "      for idx in range(word_num):\n",
        "        if text_list[idx]=='[SEP]':\n",
        "            attention_list[idx]=0.00\n",
        "        string += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \"\n",
        "      string += \"\\n}}}\"\n",
        "      f.write(string+'\\n')\n",
        "      f.write(r'''\\end{CJK*}\n",
        "\\end{document}''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCHIA3qp0eXm"
      },
      "source": [
        "# Generating Latex file for a sample\n",
        "words,weights = get_attention_weights_for_sample(attention_weights,test_text,sample_index=2400,subwords='sum')\n",
        "color='red'\n",
        "generate(words,weights,\"sample10_mini.tex\",color,rescale_value=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDLKSGg7Qut1"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBM_NmM8QuwJ"
      },
      "source": [
        "Pytorch Docs: https://pytorch.org/docs/stable/index.html<br>\n",
        "Transformer docs: https://huggingface.co/docs/transformers/index<br>\n",
        "MLTC code skeleton: https://www.kaggle.com/vpkprasanna/bert-model-with-0-845-accuracy<br>\n",
        "Pytorch BERT tutorial: https://mccormickml.com/2019/07/22/BERT-fine-tuning/<br>\n",
        "Text-Attention Visualisation: https://github.com/jiesutd/Text-Attention-Heatmap-Visualization"
      ]
    }
  ]
}