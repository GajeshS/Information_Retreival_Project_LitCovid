{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sigmoid-Importance.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_5jc35-ILaU"
      },
      "source": [
        "### GPU check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OamL0EHXB-W",
        "outputId": "4060b5b6-6733-45ea-b53b-f29be4f7f175"
      },
      "source": [
        "# GPU availability check and device initialization\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOGE28nwXjOd"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPKcZL4gIS6U"
      },
      "source": [
        "### Essential Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e3morQNZNgu"
      },
      "source": [
        "# Importing essential libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCEjnZh6IW6O"
      },
      "source": [
        "## Data Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjKv0MvgDKx3"
      },
      "source": [
        "def split(string):\n",
        "    \"\"\" To split the label values \"\"\"\n",
        "    return str(string).split(';')\n",
        "\n",
        "def preprocess_dataset(df):\n",
        "    \"\"\" Return preprocessed text and labels \"\"\"\n",
        "\n",
        "    # Append the title and abstract information for text\n",
        "    processed_data = pd.DataFrame()\n",
        "    processed_data['labels'] = df['label'].apply(split)\n",
        "    processed_data['text'] = df.apply(lambda row: row['title'] + ' [SEP] ' +row['abstract'],axis=1)\n",
        "    \n",
        "    # Converting labels to One-Hot Encoded list\n",
        "    label_mlb = MultiLabelBinarizer()\n",
        "    label_mle = label_mlb.fit_transform(processed_data['labels'])\n",
        "    processed_data['labels'] = label_mle.tolist()\n",
        "\n",
        "    # Taking and returning the text and label values\n",
        "    text = processed_data.text.values\n",
        "    labels = np.array(list(processed_data.labels.values))\n",
        "    return text, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuMh54OGDKz-"
      },
      "source": [
        "def prepare_dataloader(text,labels=np.array([]),is_test_data=False,batch_size=4,val_split=0.05):\n",
        "    \"\"\" Prepare the pytorch DataLoaders for training and validation using the training dataset \"\"\"\n",
        "\n",
        "    # Load the BERT tokenizer.\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "    # Tokenizing text\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    MAX_LEN = 512\n",
        "    for sent in text:\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text = sent,   \n",
        "            add_special_tokens = True,         #Add `[CLS]` and `[SEP]`\n",
        "            max_length= MAX_LEN,             #Max length to truncate/pad\n",
        "            pad_to_max_length = True,          #pad sentence to max length \n",
        "            return_attention_mask= True,       #Return attention mask\n",
        "        )\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    \n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    # For the test dataset\n",
        "    if is_test_data==True:\n",
        "        dataset = TensorDataset(input_ids, attention_masks)\n",
        "        dataloader = DataLoader(dataset, shuffle = False, batch_size=batch_size)\n",
        "        return dataloader\n",
        "\n",
        "    # For the training dataset\n",
        "    labels = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "    # Create a train-validation split.\n",
        "    val_size = int(val_split * len(dataset))\n",
        "    train_size = len(dataset) - val_size\n",
        "    # Divide the dataset by randomly selecting samples.\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "    # Print training and validation size\n",
        "    print('{:>5,} training samples'.format(train_size))\n",
        "    print('{:>5,} validation samples'.format(val_size))\n",
        "    \n",
        "    # Creating training and validation dataloaders\n",
        "    train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "    val_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "    return train_dataloader, val_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUjlErDAIbcP"
      },
      "source": [
        "## BERT with Attention Model classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dktsw89Ld_du"
      },
      "source": [
        "class EmbeddingAttention(nn.Module):\n",
        "    def __init__(self, num_input_features, num_hidden_features):\n",
        "        super(EmbeddingAttention,self).__init__()\n",
        "        self.l1 = nn.Linear(num_input_features,num_hidden_features)\n",
        "        self.act_1 = nn.LeakyReLU()\n",
        "        self.l2 = nn.Linear(num_hidden_features, 1) # the final attention weight for the input\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.attention_weights = torch.zeros((1,1))\n",
        "\n",
        "    def getAttentionWeights(self):\n",
        "        return self.attention_weights\n",
        "\n",
        "    def forward(self,x): # input format ==> (m,num_input_features)\n",
        "        l1_out = self.l1(x)\n",
        "        act1_out = self.act_1(l1_out)\n",
        "        l2_out = self.l2(act1_out)\n",
        "        self.attention_weights = self.sigmoid(l2_out) # this would be (m,1) dimensional\n",
        "        return torch.mul(self.attention_weights,x) # broadcasting will happen so final result is elementwide multiplication of (m,1) and (m,num_features) == (m,num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bZTr2ynMTat"
      },
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "        Bert Model for classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param   bert: a BertModel object\n",
        "        @param   classifier: a torch.nn.Module classifier\n",
        "        @param   freeze_bert (bool): Set `False` to fine_tune the Bert model\n",
        "        \"\"\"\n",
        "        super(BertClassifier,self).__init__()\n",
        "        # Specify hidden size of Bert, hidden size of our classifier, and number of labels\n",
        "        A_in,A_h = 768,50\n",
        "        D_in,H,D_out = 768,50,7\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        self.attention = EmbeddingAttention(A_in, H)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "                            nn.Linear(D_in, H),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(H, D_out))\n",
        "        \n",
        "        # Freeze the Bert Model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "    \n",
        "    def forward(self,input_ids,attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Get the BERT word embeddings\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                           attention_mask = attention_mask)\n",
        "\n",
        "        # Pass all the token embeddings (except CLS) to the attention layer\n",
        "        important_tokens = outputs[0][:,1:,:]\n",
        "        attention_out = self.attention.forward(important_tokens)\n",
        "\n",
        "        # Pool the attention-weighted embeddings of the tokens\n",
        "        mean_att = torch.mean(attention_out,dim=1)\n",
        "\n",
        "        # Feed the pooled document embedding to classifier to compute logits\n",
        "        logit = self.classifier(mean_att)\n",
        "                \n",
        "        return logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCLG6F_0IkPG"
      },
      "source": [
        "### Model training helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD7MWo-xXB-m"
      },
      "source": [
        "def save_ckp(state):\n",
        "    \"\"\" Save the model at a checkpoint \"\"\"\n",
        "    ep = state['epoch']\n",
        "    f_path = 'checkpoint_ep'+str(ep)+'.pt'\n",
        "    torch.save(state, f_path)\n",
        "    \n",
        "def load_ckp(checkpoint_fpath, model, optimizer,scheduler):\n",
        "    \"\"\" Load the model from a saved checkpoint for further training \"\"\"\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    return model,optimizer,scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hPTG9oMk7a"
      },
      "source": [
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "    \n",
        "    bert_classifier.to(device)\n",
        "    \n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                     lr=5e-5, #Default learning rate\n",
        "                     eps=1e-8 #Default epsilon value\n",
        "                     )\n",
        "    \n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    \n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps=0, # Default value\n",
        "                                              num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_iJorLSMvwO"
      },
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels.float())\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20--50000 batches\n",
        "            if (step % 50000 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        \n",
        "        # Save the model every epoch\n",
        "        checkpoint = {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "        save_ckp(checkpoint)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels.float())\n",
        "        val_loss.append(loss.item())\n",
        "        \n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = accuracy_thresh(logits.view(-1,7),b_labels.view(-1,7))\n",
        "        \n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "def accuracy_thresh(y_pred, y_true, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: \n",
        "        y_pred = y_pred.sigmoid()\n",
        "    return ((y_pred>thresh)==y_true.byte()).float().mean().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSB1u-rcFqoD"
      },
      "source": [
        "### Predictions and evaluation helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfTSp3gNa7-L"
      },
      "source": [
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities and attention weights\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "    attention_weights = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits and attention weights\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        att_weight = model.attention.getAttentionWeights()\n",
        "        all_logits.append(logits)\n",
        "        attention_weights.append(att_weight)\n",
        "    \n",
        "    # Concatenate logits and weights from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    attention_weights = torch.cat(attention_weights,dim=0)\n",
        "\n",
        "    # Apply sigmoid to calculate probabilities\n",
        "    probs = all_logits.sigmoid().cpu().numpy()\n",
        "\n",
        "    attention_weights_final = attention_weights.cpu().numpy()\n",
        "    \n",
        "    return probs,attention_weights_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2xSxs6HFyv5"
      },
      "source": [
        "def weighted_f1(labels, preds, threshold=0.5):\n",
        "    \"\"\" Converts probabilities to labels using the [threshold] and calculates metrics. \n",
        "    Parameters ---------- labels preds threshold \n",
        "    Returns ------- \"\"\" \n",
        "    preds[preds > threshold] = 1\n",
        "    preds[preds <= threshold] = 0 \n",
        "\n",
        "    scores = f1_score(labels, preds, average='weighted') \n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vONhoxsF1yO"
      },
      "source": [
        "## Training the model on the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYMjry85JBE4"
      },
      "source": [
        "### Preprocessing training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvAO8joVGDZH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBXurITNGF9N"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Information Retrieval/BC7-LitCovid-Train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN5RVnFUGF_p"
      },
      "source": [
        "train_text, train_labels = preprocess_dataset(train_data)\n",
        "train_dataloader, val_dataloader = prepare_dataloader(text=train_text,labels=train_labels,batch_size=4,val_split=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krHSr-ilGPfz"
      },
      "source": [
        "### Training..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02cpTewxXB-o"
      },
      "source": [
        "# Actual Training cell Prep\n",
        "set_seed(2021)\n",
        "epochs=20   # Set number of epochs for training\n",
        "\n",
        " # Initialize the model\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=epochs)\n",
        "\n",
        "# Load the model from a previously saved checkpoint\n",
        "# file = '/content/drive/MyDrive/Information Retrieval/Bert-Attention/checkpoint_ep10.pt'   \n",
        "# load_ckp(file,bert_classifier, optimizer, scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUHPxQ8aGb2q"
      },
      "source": [
        "# Train...\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=epochs, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpZ796veGgCx"
      },
      "source": [
        "## Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROzeJs5oGhL_"
      },
      "source": [
        "### Preprocess test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y5wsrmwGnM5"
      },
      "source": [
        "# Reading and preprocessing test dataset\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Information Retrieval/BC7-LitCovid-Dev.csv')\n",
        "test_text, test_labels = preprocess_dataset(test_data)\n",
        "test_dataloader = prepare_dataloader(text=test_text, batch_size=1, is_test_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZhqU-txGw8D"
      },
      "source": [
        "### Load the trained model (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxlUDVr7cZtx",
        "outputId": "1e395329-d8e5-47e9-bb23-9eb4ff8181f3"
      },
      "source": [
        "set_seed(2021) # Set seed for reproducibility (same as training)\n",
        "\n",
        "# Initialize the model\n",
        "final_model = BertClassifier(freeze_bert=True)\n",
        "final_model.to(device)\n",
        "\n",
        "# Load model from a file\n",
        "f_file = '/content/drive/MyDrive/Information Retrieval/Bert-Attention/checkpoint_ep20.pt'\n",
        "ckp = torch.load(f_file)\n",
        "final_model.load_state_dict(ckp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01yKU6r6HJSs"
      },
      "source": [
        "### Predictions and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFrr_xPYa8DM"
      },
      "source": [
        "# Getting the predictions and attention weights on the test set\n",
        "predictions,attention_weights = bert_predict(final_model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jToPNTAiiQc",
        "outputId": "d8dbd4e2-2964-4eed-ba4a-446c0b16ffe0"
      },
      "source": [
        "# Evaluating the predictions\n",
        "f1 = weighted_f1(test_labels,predictions)\n",
        "print(\"F1 score :\", f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score :  0.8801116258514021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGLCjq3ys9lT",
        "outputId": "5cc98a65-3dc7-4438-df0d-78c600c4322c"
      },
      "source": [
        "# LRAP score\n",
        "label_ranking_average_precision_score(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8820408363163638"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p83MNB-nHsPA"
      },
      "source": [
        "## Attention weights analysis..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ylGTP08jnpi",
        "outputId": "64af007c-e1ea-4812-f943-3d630f46de07"
      },
      "source": [
        "attention_weights.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999896"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMFxnE5NMZ-T"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXOoZDUVMVXj"
      },
      "source": [
        "Pytorch Docs: https://pytorch.org/docs/stable/index.html<br>\n",
        "Transformer docs: https://huggingface.co/docs/transformers/index<br>\n",
        "MLTC code skeleton: https://www.kaggle.com/vpkprasanna/bert-model-with-0-845-accuracy<br>\n",
        "Pytorch BERT tutorial: https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
      ]
    }
  ]
}